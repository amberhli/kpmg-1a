{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CUBEM 2019 Data Preprocessing\n",
        "\n",
        "This notebook contains preprocessing steps for the CUBEM 2019 Floor 2 dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Description\n",
        "\n",
        "Chamchuri 5 is a seven-story academic office building located at Chulalongkorn University.\n",
        "The building has an area of around 11,700 square meters (126,000 sqft).\n",
        "A typical building peak load is around 700 kW.\n",
        "\n",
        "The building is equipped with CU-BEMS -- the building energy management system,\n",
        "developed at Chulalongkorn University. Since mid-2018, CU-BEMS has been used to\n",
        "measure power consumption of building loads by type, as well as indoor temperature,\n",
        "humidity, and ambient light condition in each zone of the building.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape (rows, columns): (525600, 37)\n",
            "\n",
            "Column Names:\n",
            " ['Date', 'z1_AC1(kW)', 'z1_Light(kW)', 'z1_Plug(kW)', 'z1_S1(degC)', 'z1_S1(RH%)', 'z1_S1(lux)', 'z2_AC1(kW)', 'z2_AC2(kW)', 'z2_AC3(kW)', 'z2_AC4(kW)', 'z2_AC5(kW)', 'z2_AC6(kW)', 'z2_AC7(kW)', 'z2_AC8(kW)', 'z2_AC9(kW)', 'z2_AC10(kW)', 'z2_AC11(kW)', 'z2_AC12(kW)', 'z2_AC13(kW)', 'z2_AC14(kW)', 'z2_Light(kW)', 'z2_Plug(kW)', 'z2_S1(degC)', 'z2_S1(RH%)', 'z2_S1(lux)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z3_S1(degC)', 'z3_S1(RH%)', 'z3_S1(lux)', 'z4_AC1(kW)', 'z4_Light(kW)', 'z4_Plug(kW)', 'z4_S1(degC)', 'z4_S1(RH%)', 'z4_S1(lux)']\n",
            "\n",
            "First 5 Rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>z1_AC1(kW)</th>\n",
              "      <th>z1_Light(kW)</th>\n",
              "      <th>z1_Plug(kW)</th>\n",
              "      <th>z1_S1(degC)</th>\n",
              "      <th>z1_S1(RH%)</th>\n",
              "      <th>z1_S1(lux)</th>\n",
              "      <th>z2_AC1(kW)</th>\n",
              "      <th>z2_AC2(kW)</th>\n",
              "      <th>z2_AC3(kW)</th>\n",
              "      <th>...</th>\n",
              "      <th>z3_Plug(kW)</th>\n",
              "      <th>z3_S1(degC)</th>\n",
              "      <th>z3_S1(RH%)</th>\n",
              "      <th>z3_S1(lux)</th>\n",
              "      <th>z4_AC1(kW)</th>\n",
              "      <th>z4_Light(kW)</th>\n",
              "      <th>z4_Plug(kW)</th>\n",
              "      <th>z4_S1(degC)</th>\n",
              "      <th>z4_S1(RH%)</th>\n",
              "      <th>z4_S1(lux)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-01 00:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.85</td>\n",
              "      <td>...</td>\n",
              "      <td>0.23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-01-01 00:01:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.14</td>\n",
              "      <td>0.84</td>\n",
              "      <td>...</td>\n",
              "      <td>0.23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-01-01 00:02:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.14</td>\n",
              "      <td>0.83</td>\n",
              "      <td>...</td>\n",
              "      <td>0.23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-01-01 00:03:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.85</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.84</td>\n",
              "      <td>...</td>\n",
              "      <td>0.23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-01 00:04:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.94</td>\n",
              "      <td>1.17</td>\n",
              "      <td>0.87</td>\n",
              "      <td>...</td>\n",
              "      <td>0.23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 37 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Date  z1_AC1(kW)  z1_Light(kW)  z1_Plug(kW)  z1_S1(degC)  \\\n",
              "0  2019-01-01 00:00:00         0.0          0.31         0.09          NaN   \n",
              "1  2019-01-01 00:01:00         0.0          0.31         0.09          NaN   \n",
              "2  2019-01-01 00:02:00         0.0          0.31         0.09          NaN   \n",
              "3  2019-01-01 00:03:00         0.0          0.31         0.09          NaN   \n",
              "4  2019-01-01 00:04:00         0.0          0.31         0.09          NaN   \n",
              "\n",
              "   z1_S1(RH%)  z1_S1(lux)  z2_AC1(kW)  z2_AC2(kW)  z2_AC3(kW)  ...  \\\n",
              "0         NaN         NaN        0.00        1.15        0.85  ...   \n",
              "1         NaN         NaN        0.00        1.14        0.84  ...   \n",
              "2         NaN         NaN        0.00        1.14        0.83  ...   \n",
              "3         NaN         NaN        0.85        1.15        0.84  ...   \n",
              "4         NaN         NaN        0.94        1.17        0.87  ...   \n",
              "\n",
              "   z3_Plug(kW)  z3_S1(degC)  z3_S1(RH%)  z3_S1(lux)  z4_AC1(kW)  z4_Light(kW)  \\\n",
              "0         0.23          NaN         NaN         NaN         0.0           0.0   \n",
              "1         0.23          NaN         NaN         NaN         0.0           0.0   \n",
              "2         0.23          NaN         NaN         NaN         0.0           0.0   \n",
              "3         0.23          NaN         NaN         NaN         0.0           0.0   \n",
              "4         0.23          NaN         NaN         NaN         0.0           0.0   \n",
              "\n",
              "   z4_Plug(kW)  z4_S1(degC)  z4_S1(RH%)  z4_S1(lux)  \n",
              "0          0.0          NaN         NaN         NaN  \n",
              "1          0.0          NaN         NaN         NaN  \n",
              "2          0.0          NaN         NaN         NaN  \n",
              "3          0.0          NaN         NaN         NaN  \n",
              "4          0.0          NaN         NaN         NaN  \n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "All Columns:\n",
            " 1. Date\n",
            " 2. z1_AC1(kW)\n",
            " 3. z1_Light(kW)\n",
            " 4. z1_Plug(kW)\n",
            " 5. z1_S1(degC)\n",
            " 6. z1_S1(RH%)\n",
            " 7. z1_S1(lux)\n",
            " 8. z2_AC1(kW)\n",
            " 9. z2_AC2(kW)\n",
            "10. z2_AC3(kW)\n",
            "11. z2_AC4(kW)\n",
            "12. z2_AC5(kW)\n",
            "13. z2_AC6(kW)\n",
            "14. z2_AC7(kW)\n",
            "15. z2_AC8(kW)\n",
            "16. z2_AC9(kW)\n",
            "17. z2_AC10(kW)\n",
            "18. z2_AC11(kW)\n",
            "19. z2_AC12(kW)\n",
            "20. z2_AC13(kW)\n",
            "21. z2_AC14(kW)\n",
            "22. z2_Light(kW)\n",
            "23. z2_Plug(kW)\n",
            "24. z2_S1(degC)\n",
            "25. z2_S1(RH%)\n",
            "26. z2_S1(lux)\n",
            "27. z3_Light(kW)\n",
            "28. z3_Plug(kW)\n",
            "29. z3_S1(degC)\n",
            "30. z3_S1(RH%)\n",
            "31. z3_S1(lux)\n",
            "32. z4_AC1(kW)\n",
            "33. z4_Light(kW)\n",
            "34. z4_Plug(kW)\n",
            "35. z4_S1(degC)\n",
            "36. z4_S1(RH%)\n",
            "37. z4_S1(lux)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"../data/cu-bem/2019Floor2.csv/2019Floor2.csv\")\n",
        "\n",
        "# --- 4. Basic Info ---\n",
        "print(\"Dataset shape (rows, columns):\", df.shape)\n",
        "print(\"\\nColumn Names:\\n\", df.columns.tolist())\n",
        "print(\"\\nFirst 5 Rows:\")\n",
        "display(df.head())\n",
        "\n",
        "# Print all columns\n",
        "print(\"\\nAll Columns:\")\n",
        "for i, col in enumerate(df.columns):\n",
        "    print(f\"{i+1:2d}. {col}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Missing Values Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 525600 entries, 0 to 525599\n",
            "Data columns (total 37 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   Date          525600 non-null  object \n",
            " 1   z1_AC1(kW)    495832 non-null  float64\n",
            " 2   z1_Light(kW)  524967 non-null  float64\n",
            " 3   z1_Plug(kW)   524964 non-null  float64\n",
            " 4   z1_S1(degC)   413992 non-null  float64\n",
            " 5   z1_S1(RH%)    413992 non-null  float64\n",
            " 6   z1_S1(lux)    413992 non-null  float64\n",
            " 7   z2_AC1(kW)    495710 non-null  float64\n",
            " 8   z2_AC2(kW)    523441 non-null  float64\n",
            " 9   z2_AC3(kW)    523441 non-null  float64\n",
            " 10  z2_AC4(kW)    523441 non-null  float64\n",
            " 11  z2_AC5(kW)    524949 non-null  float64\n",
            " 12  z2_AC6(kW)    524949 non-null  float64\n",
            " 13  z2_AC7(kW)    524949 non-null  float64\n",
            " 14  z2_AC8(kW)    524949 non-null  float64\n",
            " 15  z2_AC9(kW)    524949 non-null  float64\n",
            " 16  z2_AC10(kW)   524949 non-null  float64\n",
            " 17  z2_AC11(kW)   524949 non-null  float64\n",
            " 18  z2_AC12(kW)   524949 non-null  float64\n",
            " 19  z2_AC13(kW)   524949 non-null  float64\n",
            " 20  z2_AC14(kW)   524949 non-null  float64\n",
            " 21  z2_Light(kW)  524864 non-null  float64\n",
            " 22  z2_Plug(kW)   524817 non-null  float64\n",
            " 23  z2_S1(degC)   428579 non-null  float64\n",
            " 24  z2_S1(RH%)    428582 non-null  float64\n",
            " 25  z2_S1(lux)    428580 non-null  float64\n",
            " 26  z3_Light(kW)  524966 non-null  float64\n",
            " 27  z3_Plug(kW)   524967 non-null  float64\n",
            " 28  z3_S1(degC)   423189 non-null  float64\n",
            " 29  z3_S1(RH%)    423190 non-null  float64\n",
            " 30  z3_S1(lux)    423186 non-null  float64\n",
            " 31  z4_AC1(kW)    495828 non-null  float64\n",
            " 32  z4_Light(kW)  523441 non-null  float64\n",
            " 33  z4_Plug(kW)   524817 non-null  float64\n",
            " 34  z4_S1(degC)   422315 non-null  float64\n",
            " 35  z4_S1(RH%)    422317 non-null  float64\n",
            " 36  z4_S1(lux)    422312 non-null  float64\n",
            "dtypes: float64(36), object(1)\n",
            "memory usage: 148.4+ MB\n",
            "None\n",
            "\n",
            "Missing Values per Column:\n",
            "Date                 0\n",
            "z1_AC1(kW)       29768\n",
            "z1_Light(kW)       633\n",
            "z1_Plug(kW)        636\n",
            "z1_S1(degC)     111608\n",
            "z1_S1(RH%)      111608\n",
            "z1_S1(lux)      111608\n",
            "z2_AC1(kW)       29890\n",
            "z2_AC2(kW)        2159\n",
            "z2_AC3(kW)        2159\n",
            "z2_AC4(kW)        2159\n",
            "z2_AC5(kW)         651\n",
            "z2_AC6(kW)         651\n",
            "z2_AC7(kW)         651\n",
            "z2_AC8(kW)         651\n",
            "z2_AC9(kW)         651\n",
            "z2_AC10(kW)        651\n",
            "z2_AC11(kW)        651\n",
            "z2_AC12(kW)        651\n",
            "z2_AC13(kW)        651\n",
            "z2_AC14(kW)        651\n",
            "z2_Light(kW)       736\n",
            "z2_Plug(kW)        783\n",
            "z2_S1(degC)      97021\n",
            "z2_S1(RH%)       97018\n",
            "z2_S1(lux)       97020\n",
            "z3_Light(kW)       634\n",
            "z3_Plug(kW)        633\n",
            "z3_S1(degC)     102411\n",
            "z3_S1(RH%)      102410\n",
            "z3_S1(lux)      102414\n",
            "z4_AC1(kW)       29772\n",
            "z4_Light(kW)      2159\n",
            "z4_Plug(kW)        783\n",
            "z4_S1(degC)     103285\n",
            "z4_S1(RH%)      103283\n",
            "z4_S1(lux)      103288\n",
            "dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "z1_S1(degC)     21.234399\n",
              "z1_S1(RH%)      21.234399\n",
              "z1_S1(lux)      21.234399\n",
              "z4_S1(lux)      19.651446\n",
              "z4_S1(degC)     19.650875\n",
              "z4_S1(RH%)      19.650495\n",
              "z3_S1(lux)      19.485160\n",
              "z3_S1(degC)     19.484589\n",
              "z3_S1(RH%)      19.484399\n",
              "z2_S1(degC)     18.459094\n",
              "z2_S1(lux)      18.458904\n",
              "z2_S1(RH%)      18.458524\n",
              "z2_AC1(kW)       5.686834\n",
              "z4_AC1(kW)       5.664384\n",
              "z1_AC1(kW)       5.663623\n",
              "z2_AC4(kW)       0.410769\n",
              "z4_Light(kW)     0.410769\n",
              "z2_AC2(kW)       0.410769\n",
              "z2_AC3(kW)       0.410769\n",
              "z2_Plug(kW)      0.148973\n",
              "z4_Plug(kW)      0.148973\n",
              "z2_Light(kW)     0.140030\n",
              "z2_AC6(kW)       0.123858\n",
              "z2_AC5(kW)       0.123858\n",
              "z2_AC14(kW)      0.123858\n",
              "z2_AC13(kW)      0.123858\n",
              "z2_AC8(kW)       0.123858\n",
              "z2_AC7(kW)       0.123858\n",
              "z2_AC10(kW)      0.123858\n",
              "z2_AC9(kW)       0.123858\n",
              "z2_AC12(kW)      0.123858\n",
              "z2_AC11(kW)      0.123858\n",
              "z1_Plug(kW)      0.121005\n",
              "z3_Light(kW)     0.120624\n",
              "z1_Light(kW)     0.120434\n",
              "z3_Plug(kW)      0.120434\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Quick overview of data types and missing values\n",
        "print(\"\\nData Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nMissing Values per Column:\")\n",
        "print(df.isnull().sum())\n",
        "# Percentage of missing values\n",
        "missing_pct = (df.isnull().sum() / len(df)) * 100\n",
        "display(missing_pct[missing_pct > 0].sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numeric Columns: ['z1_AC1(kW)', 'z1_Light(kW)', 'z1_Plug(kW)', 'z1_S1(degC)', 'z1_S1(RH%)', 'z1_S1(lux)', 'z2_AC1(kW)', 'z2_AC2(kW)', 'z2_AC3(kW)', 'z2_AC4(kW)', 'z2_AC5(kW)', 'z2_AC6(kW)', 'z2_AC7(kW)', 'z2_AC8(kW)', 'z2_AC9(kW)', 'z2_AC10(kW)', 'z2_AC11(kW)', 'z2_AC12(kW)', 'z2_AC13(kW)', 'z2_AC14(kW)', 'z2_Light(kW)', 'z2_Plug(kW)', 'z2_S1(degC)', 'z2_S1(RH%)', 'z2_S1(lux)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z3_S1(degC)', 'z3_S1(RH%)', 'z3_S1(lux)', 'z4_AC1(kW)', 'z4_Light(kW)', 'z4_Plug(kW)', 'z4_S1(degC)', 'z4_S1(RH%)', 'z4_S1(lux)']\n",
            "Categorical Columns: ['Date']\n",
            "Datetime Columns: []\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Separate column types\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "datetime_cols = df.select_dtypes(include=['datetime64']).columns.tolist()\n",
        "\n",
        "print(\"Numeric Columns:\", numeric_cols)\n",
        "print(\"Categorical Columns:\", categorical_cols)\n",
        "print(\"Datetime Columns:\", datetime_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[numeric_cols] = df[numeric_cols].interpolate(method='linear', limit_direction='forward')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Categorical Columns (e.g., building zone, load type)\n",
        "\n",
        "Fill with most frequent (mode) OR \"Unknown\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in categorical_cols:\n",
        "    if df[col].isna().any():\n",
        "        mode_vals = df[col].mode(dropna=True)\n",
        "        fill_val = mode_vals.iloc[0] if not mode_vals.empty else \"Unknown\"\n",
        "        df[col] = df[col].fillna(fill_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Time Series Cleaning Function\n",
        "\n",
        "Advanced function to clean and regularize time series data with proper datetime handling, deduplication, and interpolation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_time_series(\n",
        "    df: pd.DataFrame,\n",
        "    date_col: str = \"Date\",\n",
        "    group_cols: list | None = None,\n",
        "    freq: str = \"H\",\n",
        "    agg: str = \"mean\",         \n",
        "    interpolate_limit_direction: str = \"both\"\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    1) Parse datetime column\n",
        "    2) Sort + drop duplicate timestamps\n",
        "    3) Aggregate to regular frequency (e.g., hourly)\n",
        "    4) Reindex to a continuous time range\n",
        "    5) Interpolate numeric columns over time\n",
        "    \"\"\"\n",
        "    # 1) Parse datetime & drop unparsable rows\n",
        "    df = df.copy()\n",
        "    df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[date_col])\n",
        "\n",
        "    # Choose aggregator\n",
        "    if agg not in {\"mean\", \"sum\", \"median\"}:\n",
        "        raise ValueError(\"agg must be one of {'mean','sum','median'}\")\n",
        "    agg_fn = {\"mean\": \"mean\", \"sum\": \"sum\", \"median\": \"median\"}[agg]\n",
        "\n",
        "    def _per_group(g: pd.DataFrame) -> pd.DataFrame:\n",
        "        # 2) Sort & dedupe\n",
        "        g = g.sort_values(date_col).drop_duplicates(subset=[date_col])\n",
        "\n",
        "        # 3) Aggregate to target frequency (numeric columns only)\n",
        "        g = (\n",
        "            g.set_index(date_col)\n",
        "             .groupby(pd.Grouper(freq=freq))\n",
        "             .agg(agg_fn, numeric_only=True)\n",
        "        )\n",
        "\n",
        "        # 4) Reindex to continuous range\n",
        "        if len(g.index) == 0:\n",
        "            return pd.DataFrame(columns=[date_col])  # empty group\n",
        "        full_idx = pd.date_range(start=g.index.min(), end=g.index.max(), freq=freq)\n",
        "        g = g.reindex(full_idx)\n",
        "\n",
        "        # 5) Interpolate numeric columns over time\n",
        "        num_cols = g.select_dtypes(include=\"number\").columns\n",
        "        if len(num_cols) > 0:\n",
        "            g[num_cols] = g[num_cols].interpolate(\n",
        "                method=\"time\", limit_direction=interpolate_limit_direction\n",
        "            )\n",
        "\n",
        "        # Restore datetime column\n",
        "        g = g.reset_index().rename(columns={\"index\": date_col})\n",
        "        return g\n",
        "\n",
        "    if group_cols:\n",
        "        # Keep group keys alongside numeric data through the pipeline\n",
        "        # (Assumes group_cols are stable per timestamp; if not, reattach after.)\n",
        "        out = (\n",
        "            df.groupby(group_cols, group_keys=True, dropna=False)\n",
        "              .apply(_per_group)\n",
        "              .reset_index(level=list(range(len(group_cols))), drop=True)\n",
        "              .reset_index(drop=True)\n",
        "        )\n",
        "        # Reattach group columns via forward fill if needed\n",
        "        for c in group_cols:\n",
        "            if c not in out.columns:\n",
        "                # bring back as columns by repeating each group's key\n",
        "                out[c] = (\n",
        "                    df[[c]].drop_duplicates().iloc[0][0]\n",
        "                    if df[c].nunique(dropna=False) == 1 else np.nan\n",
        "                )\n",
        "        # If group labels were lost, merge back on nearest timestamps per group as needed.\n",
        "    else:\n",
        "        out = _per_group(df)\n",
        "\n",
        "    \n",
        "    print(\"Shape after datetime cleaning:\", out.shape)\n",
        "    print(\"Remaining NaNs (any):\", out.isna().any().any())\n",
        "    return out\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after datetime cleaning: (8760, 37)\n",
            "Remaining NaNs (any): False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anour\\AppData\\Local\\Temp\\ipykernel_18004\\169951731.py:33: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  .groupby(pd.Grouper(freq=freq))\n",
            "C:\\Users\\anour\\AppData\\Local\\Temp\\ipykernel_18004\\169951731.py:40: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  full_idx = pd.date_range(start=g.index.min(), end=g.index.max(), freq=freq)\n"
          ]
        }
      ],
      "source": [
        "df_clean = clean_time_series(df, date_col=\"Date\", freq=\"H\", agg=\"sum\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Remaining Missing Values: 0\n"
          ]
        }
      ],
      "source": [
        "print(\"Remaining Missing Values:\", df_clean.isnull().sum().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional Preprocessing Steps\n",
        "\n",
        "Now that missing values are handled, here are other important preprocessing techniques for building energy data:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Data Type Optimization\n",
        "\n",
        "Convert data types to save memory and improve performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory usage after optimization:\n",
            "1.2699623107910156 MB\n"
          ]
        }
      ],
      "source": [
        "# Convert float64 to float32 to save memory\n",
        "for col in df_clean.select_dtypes(include=['float64']).columns:\n",
        "    df_clean[col] = df_clean[col].astype('float32')\n",
        "\n",
        "# Convert object columns to category if they have few unique values\n",
        "for col in df_clean.select_dtypes(include=['object']).columns:\n",
        "    if df_clean[col].nunique() < 100:  # threshold for categorical conversion\n",
        "        df_clean[col] = df_clean[col].astype('category')\n",
        "\n",
        "print(\"Memory usage after optimization:\")\n",
        "print(df_clean.memory_usage(deep=True).sum() / 1024**2, \"MB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Feature Engineering\n",
        "\n",
        "Create new features from existing data for better analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New features created:\n",
            "['year', 'month', 'day', 'hour', 'day_of_week', 'is_weekend', 'season', 'z1_Total_Power(kW)', 'z2_Total_Power(kW)', 'z3_Total_Power(kW)', 'z4_Total_Power(kW)']\n"
          ]
        }
      ],
      "source": [
        "# Extract time-based features from Date column\n",
        "df_clean['year'] = df_clean['Date'].dt.year\n",
        "df_clean['month'] = df_clean['Date'].dt.month\n",
        "df_clean['day'] = df_clean['Date'].dt.day\n",
        "df_clean['hour'] = df_clean['Date'].dt.hour\n",
        "df_clean['day_of_week'] = df_clean['Date'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
        "df_clean['is_weekend'] = df_clean['day_of_week'].isin([5, 6])\n",
        "df_clean['season'] = df_clean['month'].map({12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
        "                               3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
        "                               6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
        "                               9: 'Fall', 10: 'Fall', 11: 'Fall'})\n",
        "\n",
        "# Create total power consumption per zone\n",
        "zones = ['z1', 'z2', 'z3', 'z4']\n",
        "for zone in zones:\n",
        "    # Sum all power consumption for each zone\n",
        "    power_cols = [col for col in df_clean.columns if col.startswith(zone) and '(kW)' in col]\n",
        "    if power_cols:\n",
        "        df_clean[f'{zone}_Total_Power(kW)'] = df_clean[power_cols].sum(axis=1)\n",
        "\n",
        "print(\"New features created:\")\n",
        "print([col for col in df_clean.columns if col not in numeric_cols + categorical_cols + ['Date']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Outlier Detection and Treatment\n",
        "\n",
        "Identify and handle outliers in energy consumption data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outlier Summary (IQR method):\n",
            "z1_AC1(kW): 0 outliers (0.00%)\n",
            "z1_Light(kW): 0 outliers (0.00%)\n",
            "z1_Plug(kW): 0 outliers (0.00%)\n",
            "z2_AC1(kW): 0 outliers (0.00%)\n",
            "z2_AC2(kW): 0 outliers (0.00%)\n"
          ]
        }
      ],
      "source": [
        "# Detect outliers using IQR method for power consumption columns\n",
        "power_cols = [col for col in df_clean.columns if '(kW)' in col]\n",
        "\n",
        "def detect_outliers_iqr(data, column):\n",
        "    Q1 = data[column].quantile(0.25)\n",
        "    Q3 = data[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return (data[column] < lower_bound) | (data[column] > upper_bound)\n",
        "\n",
        "outlier_summary = {}\n",
        "for col in power_cols[:5]:  # Check first 5 power columns\n",
        "    outliers = detect_outliers_iqr(df_clean, col)\n",
        "    outlier_count = outliers.sum()\n",
        "    outlier_percentage = (outlier_count / len(df_clean)) * 100\n",
        "    outlier_summary[col] = {'count': outlier_count, 'percentage': outlier_percentage}\n",
        "\n",
        "print(\"Outlier Summary (IQR method):\")\n",
        "for col, stats in outlier_summary.items():\n",
        "    print(f\"{col}: {stats['count']} outliers ({stats['percentage']:.2f}%)\")\n",
        "\n",
        "# Option 1: Cap outliers at 99th percentile\n",
        "# for col in power_cols:\n",
        "#     df_clean[col] = df_clean[col].clip(upper=df_clean[col].quantile(0.99))\n",
        "\n",
        "# Option 2: Remove extreme outliers (optional)\n",
        "# df_clean = df_clean[~df_clean[power_cols].apply(lambda x: detect_outliers_iqr(df_clean, x.name), axis=0).any(axis=1)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Data Validation\n",
        "\n",
        "Check data quality and consistency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Negative power values found: False\n",
            "Unrealistically high power values (>1000kW): True\n",
            "\n",
            "Temperature ranges:\n",
            "z1_S1(degC): 0.0Â°C to 1863.2Â°C\n",
            "z2_S1(degC): 0.0Â°C to 1848.0Â°C\n",
            "z3_S1(degC): 0.0Â°C to 1894.3Â°C\n",
            "\n",
            "Humidity ranges:\n",
            "z1_S1(RH%): 0.0% to 4528.0%\n",
            "z2_S1(RH%): 0.0% to 4966.0%\n",
            "z3_S1(RH%): 0.0% to 5054.2%\n",
            "\n",
            "Duplicate timestamps: 0\n",
            "Missing hours in dataset: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anour\\AppData\\Local\\Temp\\ipykernel_18004\\2389194787.py:28: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  hourly_counts = df_clean.groupby(df_clean['Date'].dt.floor('H')).size()\n"
          ]
        }
      ],
      "source": [
        "# Check for negative power values (shouldn't exist for consumption)\n",
        "negative_power = (df_clean[power_cols] < 0).any().any()\n",
        "print(f\"Negative power values found: {negative_power}\")\n",
        "\n",
        "# Check for unrealistic power values (e.g., > 1000 kW for a single zone)\n",
        "high_power = (df_clean[power_cols] > 1000).any().any()\n",
        "print(f\"Unrealistically high power values (>1000kW): {high_power}\")\n",
        "\n",
        "# Check temperature ranges (should be reasonable for indoor/outdoor)\n",
        "temp_cols = [col for col in df_clean.columns if 'degC' in col]\n",
        "if temp_cols:\n",
        "    print(f\"\\nTemperature ranges:\")\n",
        "    for col in temp_cols[:3]:  # Check first 3 temperature columns\n",
        "        print(f\"{col}: {df_clean[col].min():.1f}Â°C to {df_clean[col].max():.1f}Â°C\")\n",
        "\n",
        "# Check humidity ranges (should be 0-100%)\n",
        "humidity_cols = [col for col in df_clean.columns if 'RH%' in col]\n",
        "if humidity_cols:\n",
        "    print(f\"\\nHumidity ranges:\")\n",
        "    for col in humidity_cols[:3]:  # Check first 3 humidity columns\n",
        "        print(f\"{col}: {df_clean[col].min():.1f}% to {df_clean[col].max():.1f}%\")\n",
        "\n",
        "# Check for duplicate timestamps\n",
        "duplicate_timestamps = df_clean['Date'].duplicated().sum()\n",
        "print(f\"\\nDuplicate timestamps: {duplicate_timestamps}\")\n",
        "\n",
        "# Check data completeness by hour\n",
        "hourly_counts = df_clean.groupby(df_clean['Date'].dt.floor('H')).size()\n",
        "missing_hours = hourly_counts[hourly_counts == 0].count()\n",
        "print(f\"Missing hours in dataset: {missing_hours}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Data Scaling and Normalization\n",
        "\n",
        "Prepare data for machine learning models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scaling applied to power consumption columns\n",
            "Original power data range: 0.00 to 3178.45\n",
            "Scaled power data range: -3.55 to 48.18\n",
            "Scaler saved as 'power_scaler.pkl'\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "\n",
        "# Choose scaling method based on data characteristics\n",
        "# StandardScaler: good for normally distributed data\n",
        "# MinMaxScaler: good for bounded data (0-1 range)\n",
        "# RobustScaler: good for data with outliers\n",
        "\n",
        "# Example: Scale power consumption data\n",
        "scaler = StandardScaler()\n",
        "power_data_scaled = scaler.fit_transform(df_clean[power_cols])\n",
        "\n",
        "# Create a copy with scaled data\n",
        "df_scaled = df_clean.copy()\n",
        "df_scaled[power_cols] = power_data_scaled\n",
        "\n",
        "print(\"Scaling applied to power consumption columns\")\n",
        "print(f\"Original power data range: {df_clean[power_cols].min().min():.2f} to {df_clean[power_cols].max().max():.2f}\")\n",
        "print(f\"Scaled power data range: {df_scaled[power_cols].min().min():.2f} to {df_scaled[power_cols].max().max():.2f}\")\n",
        "\n",
        "# Save scaler for later use (inverse transform)\n",
        "import joblib\n",
        "joblib.dump(scaler, 'power_scaler.pkl')\n",
        "print(\"Scaler saved as 'power_scaler.pkl'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Final Data Summary\n",
        "\n",
        "Summary of the preprocessed dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== PREPROCESSED DATASET SUMMARY ===\n",
            "Final shape: (8760, 48)\n",
            "Date range: 2019-01-01 00:00:00 to 2019-12-31 23:00:00\n",
            "Total duration: 364 days\n",
            "Memory usage: 2.03 MB\n",
            "\n",
            "Column types:\n",
            "- Numeric columns: 45\n",
            "- Categorical columns: 0\n",
            "- Object columns: 1\n",
            "\n",
            "Missing values:\n",
            "No missing values remaining!\n",
            "\n",
            "Data quality checks:\n",
            "- Negative power values: False\n",
            "- Duplicate timestamps: 0\n",
            "- Data completeness: -0.01%\n",
            "\n",
            "Dataset is ready for analysis!\n"
          ]
        }
      ],
      "source": [
        "# Final dataset summary\n",
        "print(\"=== PREPROCESSED DATASET SUMMARY ===\")\n",
        "print(f\"Final shape: {df_clean.shape}\")\n",
        "print(f\"Date range: {df_clean['Date'].min()} to {df_clean['Date'].max()}\")\n",
        "print(f\"Total duration: {(df_clean['Date'].max() - df_clean['Date'].min()).days} days\")\n",
        "print(f\"Memory usage: {df_clean.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "print(f\"\\nColumn types:\")\n",
        "print(f\"- Numeric columns: {len(df_clean.select_dtypes(include=[np.number]).columns)}\")\n",
        "print(f\"- Categorical columns: {len(df_clean.select_dtypes(include=['category']).columns)}\")\n",
        "print(f\"- Object columns: {len(df_clean.select_dtypes(include=['object']).columns)}\")\n",
        "\n",
        "print(f\"\\nMissing values:\")\n",
        "missing_summary = df_clean.isnull().sum()\n",
        "missing_cols = missing_summary[missing_summary > 0]\n",
        "if len(missing_cols) > 0:\n",
        "    print(\"Columns with missing values:\")\n",
        "    for col, count in missing_cols.items():\n",
        "        print(f\"  {col}: {count} ({count/len(df_clean)*100:.2f}%)\")\n",
        "else:\n",
        "    print(\"No missing values remaining!\")\n",
        "\n",
        "print(f\"\\nData quality checks:\")\n",
        "print(f\"- Negative power values: {(df_clean[power_cols] < 0).any().any()}\")\n",
        "print(f\"- Duplicate timestamps: {df_clean['Date'].duplicated().sum()}\")\n",
        "print(f\"- Data completeness: {((df_clean['Date'].max() - df_clean['Date'].min()).total_seconds() / 3600 - len(df_clean)) / ((df_clean['Date'].max() - df_clean['Date'].min()).total_seconds() / 3600) * 100:.2f}%\")\n",
        "\n",
        "print(f\"\\nDataset is ready for analysis!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>z1_AC1(kW)</th>\n",
              "      <th>z1_Light(kW)</th>\n",
              "      <th>z1_Plug(kW)</th>\n",
              "      <th>z1_S1(degC)</th>\n",
              "      <th>z1_S1(RH%)</th>\n",
              "      <th>z1_S1(lux)</th>\n",
              "      <th>z2_AC1(kW)</th>\n",
              "      <th>z2_AC2(kW)</th>\n",
              "      <th>z2_AC3(kW)</th>\n",
              "      <th>...</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>is_weekend</th>\n",
              "      <th>season</th>\n",
              "      <th>z1_Total_Power(kW)</th>\n",
              "      <th>z2_Total_Power(kW)</th>\n",
              "      <th>z3_Total_Power(kW)</th>\n",
              "      <th>z4_Total_Power(kW)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-01 00:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.650000</td>\n",
              "      <td>5.40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.169998</td>\n",
              "      <td>68.339996</td>\n",
              "      <td>50.480000</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>Winter</td>\n",
              "      <td>24.049999</td>\n",
              "      <td>316.859985</td>\n",
              "      <td>22.580000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-01-01 01:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>5.40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.990002</td>\n",
              "      <td>68.620003</td>\n",
              "      <td>50.880001</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>Winter</td>\n",
              "      <td>24.240000</td>\n",
              "      <td>337.160034</td>\n",
              "      <td>23.160000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-01-01 02:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.860001</td>\n",
              "      <td>5.42</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.310001</td>\n",
              "      <td>68.510002</td>\n",
              "      <td>50.810001</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>Winter</td>\n",
              "      <td>24.280001</td>\n",
              "      <td>334.160004</td>\n",
              "      <td>23.180000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-01-01 03:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.540001</td>\n",
              "      <td>5.39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.500000</td>\n",
              "      <td>66.750000</td>\n",
              "      <td>49.470001</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>Winter</td>\n",
              "      <td>23.930000</td>\n",
              "      <td>326.170013</td>\n",
              "      <td>22.970001</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-01 04:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.730000</td>\n",
              "      <td>5.40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.400002</td>\n",
              "      <td>67.559998</td>\n",
              "      <td>50.169998</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>Winter</td>\n",
              "      <td>24.129999</td>\n",
              "      <td>332.079987</td>\n",
              "      <td>23.110001</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 48 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Date  z1_AC1(kW)  z1_Light(kW)  z1_Plug(kW)  z1_S1(degC)  \\\n",
              "0 2019-01-01 00:00:00         0.0     18.650000         5.40          0.0   \n",
              "1 2019-01-01 01:00:00         0.0     18.840000         5.40          0.0   \n",
              "2 2019-01-01 02:00:00         0.0     18.860001         5.42          0.0   \n",
              "3 2019-01-01 03:00:00         0.0     18.540001         5.39          0.0   \n",
              "4 2019-01-01 04:00:00         0.0     18.730000         5.40          0.0   \n",
              "\n",
              "   z1_S1(RH%)  z1_S1(lux)  z2_AC1(kW)  z2_AC2(kW)  z2_AC3(kW)  ...  month  \\\n",
              "0         0.0         0.0   33.169998   68.339996   50.480000  ...      1   \n",
              "1         0.0         0.0   37.990002   68.620003   50.880001  ...      1   \n",
              "2         0.0         0.0   37.310001   68.510002   50.810001  ...      1   \n",
              "3         0.0         0.0   36.500000   66.750000   49.470001  ...      1   \n",
              "4         0.0         0.0   37.400002   67.559998   50.169998  ...      1   \n",
              "\n",
              "   day  hour  day_of_week  is_weekend  season  z1_Total_Power(kW)  \\\n",
              "0    1     0            1       False  Winter           24.049999   \n",
              "1    1     1            1       False  Winter           24.240000   \n",
              "2    1     2            1       False  Winter           24.280001   \n",
              "3    1     3            1       False  Winter           23.930000   \n",
              "4    1     4            1       False  Winter           24.129999   \n",
              "\n",
              "   z2_Total_Power(kW)  z3_Total_Power(kW)  z4_Total_Power(kW)  \n",
              "0          316.859985           22.580000                 0.0  \n",
              "1          337.160034           23.160000                 0.0  \n",
              "2          334.160004           23.180000                 0.0  \n",
              "3          326.170013           22.970001                 0.0  \n",
              "4          332.079987           23.110001                 0.0  \n",
              "\n",
              "[5 rows x 48 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_clean.head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
